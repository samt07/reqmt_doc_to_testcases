{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef896fc-1a11-4e21-95bb-8192f2fb31f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.60.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting python-docx\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\softwares\\python\\lib\\site-packages (from openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\softwares\\python\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: sniffio in e:\\softwares\\python\\lib\\site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx)\n",
      "  Downloading lxml-5.3.0-cp313-cp313-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\softwares\\python\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\softwares\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\softwares\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\softwares\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.27.2-cp313-cp313-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in e:\\softwares\\python\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.60.2-py3-none-any.whl (456 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.2-cp313-cp313-win_amd64.whl (203 kB)\n",
      "Downloading lxml-5.3.0-cp313-cp313-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.8/3.8 MB 23.3 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 20.2 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, python-dotenv, lxml, jiter, distro, annotated-types, python-docx, pydantic-core, pydantic, openai\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.8.2 lxml-5.3.0 openai-1.60.2 pydantic-2.10.6 pydantic-core-2.27.2 python-docx-1.1.2 python-dotenv-1.0.1 tqdm-4.67.1 typing-extensions-4.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai python-dotenv python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950a084a-7f92-4669-af62-f07cb121da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9f734f-ed6f-44f6-accb-594f9ca4843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReqDoc:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def extract(self):\n",
    "        \"\"\"\n",
    "        Reads the content of a .docx file and returns the paragraphs as a list of strings.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if the file exists\n",
    "            if not os.path.exists(self.file_path):\n",
    "                raise FileNotFoundError(f\"The file {self.file_path} was not found.\")\n",
    "\n",
    "            # Attempt to open and read the document\n",
    "            doc = Document(self.file_path)\n",
    "            text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "            return text\n",
    "\n",
    "        except FileNotFoundError as fnf_error:\n",
    "            print(fnf_error)\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "008f485a-5718-48f6-b408-06eb6d59d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "#If Running in Google Colab, set up env variable as per the instructions in README.md file.\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6110ff3-74bc-430a-8051-7d86a216f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up system prompt for extracting just the requirements from the document\n",
    "\n",
    "req_doc_system_prompt = \"You are provided with a complete requirements specifications document. \\\n",
    "You are able to decide which content from that document are related to actual requirements, identify each requirement as \\\n",
    "functional or non-functional and list them all.\\n\"\n",
    "req_doc_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "req_doc_system_prompt += \"\"\"\n",
    "{\n",
    "    \"requirements\": [\n",
    "        {\"RequirementNo\": \"FR-01\", \"Requirement Description\": \"description of this functional requirement goes here\"},\n",
    "        {\"RequirementNo\": \"FR-02\": \"Requirement Description\": \"description of this functional requirement goes here\"},\n",
    "        {\"RequirementNo\": \"NFR-01\": \"Requirement Description\": \"description of this non-functional requirement goes here\"},\n",
    "        {\"RequirementNo\": \"NFR-02\": \"Requirement Description\": \"description of this non-functional requirement goes here\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20460e45-c1b7-4dc4-ab07-932235c19895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up user prompt, sending in the requirements doc as input and calling the ReqDoc.extract function. Key to note here is the explicit instructions to\n",
    "#respond in JSON format.\n",
    "\n",
    "def req_doc_user_prompt(doc):\n",
    "    user_prompt = \"Here is the contents from a requirement document.\\n\"\n",
    "    user_prompt += f\"{doc.extract()} \\n\"\n",
    "    user_prompt += \"Please scan through the document and extract only the  actual requirements. For example, ignore sections or \\\n",
    "paragraphs such as Approvers, table of contents and similar sections which are not really requirements.\\\n",
    "You must respond in a JSON format\"\n",
    "    user_prompt = user_prompt[:25_000] # Truncate if more than 25,000 characters\n",
    "    return user_prompt\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a9f0f84-69a0-4971-a545-5bb40c2f9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to call chatgpt-4o-mini model with the user and system prompts set above and returning the json formatted result obtained from chatgpt\n",
    "\n",
    "def get_requirements(doc):\n",
    "    reqdoc = ReqDoc(doc)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": req_doc_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": req_doc_user_prompt(reqdoc)}\n",
    "        ],\n",
    "      response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9bb04ef-78d3-4e0f-9ed1-59a961a0663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file requirements.docx was not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'requirements': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_requirements(\"requirements.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8618c-1dfe-4030-bad8-405731294c93",
   "metadata": {},
   "source": [
    "### Next, we will make another call to gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db2c1eb3-7740-43a4-9c0b-37b7e70c739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up system prompt to ask for test cases in table format\n",
    "\n",
    "system_prompt = \"You are an assitant that receives a list of functional and non functional requirements in JSON format. You are the expert in generating unit test cases for each requirement. \\\n",
    "You will create as many different test cases as needed for each requirement and produce a result in a table. Order the table by requirement No. Provide clear details on test case pass criteria. \\\n",
    "The table will contain the following columns. \\\n",
    "1.S No\\\n",
    "2.Requirement No\\\n",
    "3.Requirement Description\\\n",
    "4.Test Case ID\\\n",
    "5.Test case summary\\\n",
    "6.Test case description\\\n",
    "7.Success criteria \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4cd2bdf-e1bd-43ff-85fa-760ba39ed8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up user prompt passing in the req doc file. This in turn will call the get_requirements function, which will make a call to chatgpt.\n",
    "\n",
    "def get_testcase_user_prompt(reqdoc):\n",
    "    user_prompt = \"You are looking at the following list of requirements. \\n\"\n",
    "    user_prompt += f\"{get_requirements(reqdoc)}\\n\"\n",
    "    user_prompt += \"Prepare unit test cases for each of these requirements in a table and send that table as response. \\n\"\n",
    "    user_prompt += user_prompt[:25000]\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d859e2-e5bb-4bd6-ab59-5ad967d5d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the 2nd call to chatgpt to get test cases. display(Markdown) will take care of producing a neatly formatted table output.\n",
    "def create_testcase_doc(reqdoc):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_testcase_user_prompt(reqdoc)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0612d662-7047-4620-aa1c-2eb1c3d715cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is a table with unit test cases for each of the provided requirements:\n",
       "\n",
       "| S No | Requirement No | Requirement Description                                              | Test Case ID | Test Case Summary                           | Test Case Description                                                                                | Success Criteria                           |\n",
       "|------|----------------|---------------------------------------------------------------------|---------------|---------------------------------------------|-----------------------------------------------------------------------------------------------------|-------------------------------------------|\n",
       "| 1    | FR-01          | Users can submit feedback via an online form.                      | TC_FR01_001   | Valid feedback submission                   | Verify that a user can submit valid feedback through the online form.                              | Feedback is successfully recorded in the system. |\n",
       "| 2    | FR-01          | Users can submit feedback via an online form.                      | TC_FR01_002   | Invalid feedback submission                 | Verify that a user receives an error message on submitting invalid feedback.                        | Error message is displayed as expected.                 |\n",
       "| 3    | FR-01          | Users can submit feedback via an online form.                      | TC_FR01_003   | Empty feedback submission                   | Verify that a user cannot submit the feedback form if no content is provided.                       | Error message specific to empty form is shown.       |\n",
       "| 4    | FR-02          | Feedback can be categorized by type (e.g., product, service).      | TC_FR02_001   | Validate feedback categorization           | Verify that feedback submitted can be categorized correctly into predefined types.                  | Feedback is categorized correctly.           |\n",
       "| 5    | FR-02          | Feedback can be categorized by type (e.g., product, service).      | TC_FR02_002   | Invalid category selection                  | Verify that an error is thrown when an invalid category is selected during feedback submission.     | Error message for invalid category is shown.       |\n",
       "| 6    | FR-03          | Administrators can generate detailed reports.                      | TC_FR03_001   | Generate feedback report                    | Verify that an administrator can generate a feedback report successfully.                          | Report is generated and contains correct data.     |\n",
       "| 7    | FR-03          | Administrators can generate detailed reports.                      | TC_FR03_002   | Empty report request                        | Verify the behavior when an administrator requests a report without any filters or parameters.     | Appropriate message regarding empty filters.     |\n",
       "| 8    | NFR-01         | The system must support at least 10,000 concurrent users.           | TC_NFR01_001  | Test concurrent user load                   | Simulate a load of 10,000 users accessing the system concurrently.                                 | System remains responsive and functional.       |\n",
       "| 9    | NFR-01         | The system must support at least 10,000 concurrent users.           | TC_NFR01_002  | Test with 10,001 users                      | Simulate a load of 10,001 users accessing the system concurrently.                                 | System indicates it cannot support beyond 10,000.  |\n",
       "| 10   | NFR-02         | The feedback portal must load within 3 seconds for all pages.      | TC_NFR02_001  | Validate page load time                     | Measure the load time for multiple pages in the feedback portal.                                   | All pages load in less than 3 seconds.    |\n",
       "| 11   | NFR-02         | The feedback portal must load within 3 seconds for all pages.      | TC_NFR02_002  | Stress test Pages load time                 | Measure page load time when simulated with high concurrency (e.g., 100 users).                     | All pages load in less than 3 seconds.    |\n",
       "| 12   | NFR-03         | Data must be encrypted during transmission and at rest.             | TC_NFR03_001  | Validate data encryption in transmission    | Verify that data is encrypted while being sent from the user device to the server.                  | Data captured in transit is encrypted.       |\n",
       "| 13   | NFR-03         | Data must be encrypted during transmission and at rest.             | TC_NFR03_002  | Validate data encryption at rest            | Verify that stored data in the database is encrypted.                                             | Data in the database appears as encrypted.       |\n",
       "\n",
       "This table summarizes the unit test cases devised for each requirement while ensuring clarity on the test case descriptions and success criteria."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The final piece of code. Ensure the requirements doc file is in the same path where the code is running and provide that filename instead.\n",
    "create_testcase_doc(\"reqdoc.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabad5a-f997-45d3-8ed7-42bd9d5427e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
