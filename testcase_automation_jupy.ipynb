{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "it1JLoxrSqO1",
   "metadata": {
    "id": "it1JLoxrSqO1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in e:\\softwares\\python\\lib\\site-packages (1.60.2)\n",
      "Requirement already satisfied: python-docx in e:\\softwares\\python\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: python-dotenv in e:\\softwares\\python\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in e:\\softwares\\python\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\softwares\\python\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\softwares\\python\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\softwares\\python\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in e:\\softwares\\python\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in e:\\softwares\\python\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in e:\\softwares\\python\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in e:\\softwares\\python\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in e:\\softwares\\python\\lib\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\softwares\\python\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\softwares\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\softwares\\python\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\softwares\\python\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\softwares\\python\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in e:\\softwares\\python\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in e:\\softwares\\python\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai python-docx python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950a084a-7f92-4669-af62-f07cb121da56",
   "metadata": {
    "id": "950a084a-7f92-4669-af62-f07cb121da56"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9f734f-ed6f-44f6-accb-594f9ca4843d",
   "metadata": {
    "id": "ab9f734f-ed6f-44f6-accb-594f9ca4843d"
   },
   "outputs": [],
   "source": [
    "class ReqDoc:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def extract(self):\n",
    "        \"\"\"\n",
    "        Reads the content of a .docx file and returns the paragraphs as a list of strings.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if the file exists\n",
    "            if not os.path.exists(self.file_path):\n",
    "                raise FileNotFoundError(f\"The file {self.file_path} was not found.\")\n",
    "\n",
    "            # Attempt to open and read the document\n",
    "            doc = Document(self.file_path)\n",
    "            text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "            return text\n",
    "\n",
    "        except FileNotFoundError as fnf_error:\n",
    "            print(fnf_error)\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008f485a-5718-48f6-b408-06eb6d59d7f9",
   "metadata": {
    "id": "008f485a-5718-48f6-b408-06eb6d59d7f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good!\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj') and len(api_key)>10:\n",
    "    print(\"API key looks good!\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key. Please check!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6110ff3-74bc-430a-8051-7d86a216f0fb",
   "metadata": {
    "id": "b6110ff3-74bc-430a-8051-7d86a216f0fb"
   },
   "outputs": [],
   "source": [
    "#Set up system prompt for extracting just the requirements from the document\n",
    "\n",
    "req_doc_system_prompt = \"You are provided with a complete requirements specifications document. \\\n",
    "You are able to decide which content from that document are related to actual requirements, identify each requirement as \\\n",
    "functional or non-functional and list them all.\\n\"\n",
    "req_doc_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "req_doc_system_prompt += \"\"\"\n",
    "{\n",
    "    \"requirements\": [\n",
    "        {\"RequirementNo\": \"FR-01\", \"Requirement Description\": \"description of this functional requirement goes here\"},\n",
    "        {\"RequirementNo\": \"FR-02\": \"Requirement Description\": \"description of this functional requirement goes here\"},\n",
    "        {\"RequirementNo\": \"NFR-01\": \"Requirement Description\": \"description of this non-functional requirement goes here\"},\n",
    "        {\"RequirementNo\": \"NFR-02\": \"Requirement Description\": \"description of this non-functional requirement goes here\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20460e45-c1b7-4dc4-ab07-932235c19895",
   "metadata": {
    "id": "20460e45-c1b7-4dc4-ab07-932235c19895"
   },
   "outputs": [],
   "source": [
    "#Set up user prompt, sending in the requirements doc as input and calling the ReqDoc.extract function. Key to note here is the explicit instructions to\n",
    "#respond in JSON format.\n",
    "\n",
    "def req_doc_user_prompt(doc):\n",
    "    user_prompt = \"Here is the contents from a requirement document.\\n\"\n",
    "    user_prompt += f\"{doc.extract()} \\n\"\n",
    "    user_prompt += \"Please scan through the document and extract only the  actual requirements. For example, ignore sections or \\\n",
    "paragraphs such as Approvers, table of contents and similar sections which are not really requirements.\\\n",
    "You must respond in a JSON format\"\n",
    "    user_prompt = user_prompt[:25_000] # Truncate if more than 25,000 characters\n",
    "    return user_prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9f0f84-69a0-4971-a545-5bb40c2f9891",
   "metadata": {
    "id": "3a9f0f84-69a0-4971-a545-5bb40c2f9891"
   },
   "outputs": [],
   "source": [
    "#Function to call chatgpt-4o-mini model with the user and system prompts set above and returning the json formatted result obtained from chatgpt\n",
    "\n",
    "def get_requirements(doc):\n",
    "    reqdoc = ReqDoc(doc)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": req_doc_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": req_doc_user_prompt(reqdoc)}\n",
    "        ],\n",
    "      response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9bb04ef-78d3-4e0f-9ed1-59a961a0663e",
   "metadata": {
    "id": "f9bb04ef-78d3-4e0f-9ed1-59a961a0663e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'requirements': [{'RequirementNo': 'FR-01',\n",
       "   'Requirement Description': 'Users can submit feedback via an online form.'},\n",
       "  {'RequirementNo': 'FR-02',\n",
       "   'Requirement Description': 'Feedback can be categorized by type (e.g., product, service).'},\n",
       "  {'RequirementNo': 'FR-03',\n",
       "   'Requirement Description': 'Administrators can generate detailed reports.'},\n",
       "  {'RequirementNo': 'NFR-01',\n",
       "   'Requirement Description': 'The system must support at least 10,000 concurrent users.'},\n",
       "  {'RequirementNo': 'NFR-02',\n",
       "   'Requirement Description': 'The feedback portal must load within 3 seconds for all pages.'},\n",
       "  {'RequirementNo': 'NFR-03',\n",
       "   'Requirement Description': 'Data must be encrypted during transmission and at rest.'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uncomment and run this if you want to see the extracted requriements in json format.\n",
    "get_requirements(\"reqdoc.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8618c-1dfe-4030-bad8-405731294c93",
   "metadata": {
    "id": "1fe8618c-1dfe-4030-bad8-405731294c93"
   },
   "source": [
    "### Next, we will make another call to gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2c1eb3-7740-43a4-9c0b-37b7e70c739b",
   "metadata": {
    "id": "db2c1eb3-7740-43a4-9c0b-37b7e70c739b"
   },
   "outputs": [],
   "source": [
    "#Set up system prompt to ask for test cases in table format\n",
    "\n",
    "system_prompt = \"You are an assitant that receives a list of functional and non functional requirements in JSON format. You are the expert in generating unit test cases for each requirement. \\\n",
    "You will create as many different test cases as needed for each requirement and produce a result in a table. Order the table by requirement No. Provide clear details on test case pass criteria. \\\n",
    "The table will contain the following columns. \\\n",
    "1.S No\\\n",
    "2.Requirement No\\\n",
    "3.Requirement Description\\\n",
    "4.Test Case ID\\\n",
    "5.Test case summary\\\n",
    "6.Test case description\\\n",
    "7.Success criteria \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4cd2bdf-e1bd-43ff-85fa-760ba39ed8c5",
   "metadata": {
    "id": "c4cd2bdf-e1bd-43ff-85fa-760ba39ed8c5"
   },
   "outputs": [],
   "source": [
    "# Set up user prompt passing in the req doc file. This in turn will call the get_requirements function, which will make a call to chatgpt.\n",
    "\n",
    "def get_testcase_user_prompt(reqdoc):\n",
    "    user_prompt = \"You are looking at the following list of requirements. \\n\"\n",
    "    user_prompt += f\"{get_requirements(reqdoc)}\\n\"\n",
    "    user_prompt += \"Prepare unit test cases for each of these requirements in a table and send that table as response. \\n\"\n",
    "    user_prompt += user_prompt[:25000]\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59d859e2-e5bb-4bd6-ab59-5ad967d5d2e0",
   "metadata": {
    "id": "59d859e2-e5bb-4bd6-ab59-5ad967d5d2e0"
   },
   "outputs": [],
   "source": [
    "#This is the 2nd call to chatgpt to get test cases. display(Markdown) will take care of producing a neatly formatted table output.\n",
    "def create_testcase_doc(reqdoc):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_testcase_user_prompt(reqdoc)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0612d662-7047-4620-aa1c-2eb1c3d715cb",
   "metadata": {
    "id": "0612d662-7047-4620-aa1c-2eb1c3d715cb"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Below are the unit test cases for the provided list of functional and non-functional requirements, organized in a table format.\n",
       "\n",
       "| S No | Requirement No | Requirement Description                                                | Test Case ID | Test Case Summary                                       | Test Case Description                                                                                                 | Success Criteria                                                 |\n",
       "|------|----------------|----------------------------------------------------------------------|---------------|--------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------|\n",
       "| 1    | FR-01          | Users can submit feedback via an online form.                       | TC_FR-01-01   | Valid Submission                                        | Verify that a valid user can successfully submit feedback through the online form.                                    | Feedback is submitted successfully and stored in the database.   |\n",
       "| 2    | FR-01          | Users can submit feedback via an online form.                       | TC_FR-01-02   | Invalid Submission                                      | Verify that an error message is displayed when a user attempts to submit an empty feedback form.                      | Error message \"Feedback cannot be empty\" is displayed.         |\n",
       "| 3    | FR-02          | Feedback can be categorized by type (e.g., product, service).      | TC_FR-02-01   | Categorization by Type                                  | Check that feedback can be categorized correctly when submitted.                                                      | Feedback is categorized correctly in the database.               |\n",
       "| 4    | FR-02          | Feedback can be categorized by type (e.g., product, service).      | TC_FR-02-02   | Invalid Category Handling                                | Check that an error message is shown if a user selects an invalid category.                                           | Error message \"Invalid category selected\" is displayed.         |\n",
       "| 5    | FR-03          | Administrators can generate detailed reports.                       | TC_FR-03-01   | Report Generation                                       | Verify that an administrator can generate a report successfully.                                                     | Report is generated and downloaded without errors.               |\n",
       "| 6    | FR-03          | Administrators can generate detailed reports.                       | TC_FR-03-02   | Empty Report Generation                                  | Verify that appropriate message is shown when there are no feedback entries to report on.                             | Message \"No feedback entries found\" is displayed.                |\n",
       "| 7    | NFR-01         | The system must support at least 10,000 concurrent users.          | TC_NFR-01-01  | Concurrent Users Load Test                              | Simulate 10,000 concurrent users accessing the system to check for performance issues.                                 | System remains operational without significant slowdowns.       |\n",
       "| 8    | NFR-02         | The feedback portal must load within 3 seconds for all pages.     | TC_NFR-02-01  | Page Load Time Test                                    | Measure the time taken for each page of the feedback portal to load.                                                  | All pages load within 3 seconds.                                 |\n",
       "| 9    | NFR-03         | Data must be encrypted during transmission and at rest.            | TC_NFR-03-01  | Data Transmission Encryption Test                       | Verify that data is encrypted during transmission using encryption protocols (e.g., TLS).                             | Data during transmission is encrypted and not readable in transit.  |\n",
       "| 10   | NFR-03         | Data must be encrypted during transmission and at rest.            | TC_NFR-03-02  | Data at Rest Encryption Test                            | Check that stored feedback data in the database is encrypted and cannot be accessed in plain text.                    | Data in the database is encrypted and unreadable without decryption. |\n",
       "\n",
       "This table includes a comprehensive set of test cases addressing each requirement with clear pass criteria for effective validation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The final piece of code. Provide the uploaded requirements filename below.\n",
    "create_testcase_doc(\"reqdoc.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabad5a-f997-45d3-8ed7-42bd9d5427e0",
   "metadata": {
    "id": "4fabad5a-f997-45d3-8ed7-42bd9d5427e0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
